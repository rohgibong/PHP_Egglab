from flask import Flask, Response
import cv2
import threading
from inference_sdk import InferenceHTTPClient
from PIL import Image

app = Flask(__name__)

# Roboflow API 설정
CLIENT = InferenceHTTPClient(
    api_url="https://detect.roboflow.com",
    api_key="6uSLG3zGae4M5VcFjJnn"
)

model_ids = {
    "ppe": "personal-protective-equipment-combined-model/4",
    "fall": "fall-7lbue/1"
}

# 클래스 이름과 색상 매핑
class_colors = {
    "fall": (0, 0, 255),    # Red
    "NO-hardhat": (0, 255, 0)  # Green
}

class CameraStream:
    def __init__(self, camera_index):
        self.camera_index = camera_index
        self.predictions = []
        self.predictions_lock = threading.Lock()
        self.cap = cv2.VideoCapture(camera_index)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.thread = threading.Thread(target=self.update)
        self.thread.daemon = True
        self.thread.start()

    def update(self):
        while True:
            ret, frame = self.cap.read()
            if ret:
                threading.Thread(target=self.predict_frame_async, args=(frame.copy(),)).start()
                with self.predictions_lock:
                    current_predictions = self.predictions
                fall_detected = any(pred['class'] == 'fall' for pred in current_predictions)
                no_hardhat_detected = any(pred['class'] == 'NO-hardhat' for pred in current_predictions)
                if fall_detected:
                    # 화면 프레임 전체에 빨간 얇은 테두리 추가
                    frame = cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 2)
                if no_hardhat_detected:
                    # 화면 프레임 전체에 초록 얇은 테두리 추가
                    frame = cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 255, 0), 2)
                for pred in current_predictions:
                    x1 = int(pred['x'] - pred['width'] / 2)
                    y1 = int(pred['y'] - pred['height'] / 2)
                    x2 = int(pred['x'] + pred['width'] / 2)
                    y2 = int(pred['y'] + pred['height'] / 2)
                    class_name = pred['class']
                    color = class_colors.get(class_name, (0, 255, 0))
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    cv2.putText(frame, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                ret, buffer = cv2.imencode('.jpg', frame)
                frame = buffer.tobytes()
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
            else:
                break
        self.cap.release()

    def predict_frame_async(self, frame):
        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        ppe_result = CLIENT.infer(pil_img, model_id=model_ids["ppe"])
        fall_result = CLIENT.infer(pil_img, model_id=model_ids["fall"])
        with self.predictions_lock:
            self.predictions = ppe_result['predictions'] + fall_result['predictions']

    def generate_frames(self):
        return self.update()

camera_streams = [CameraStream(0), CameraStream(1)]

@app.route('/video_feed/<int:camera_index>')
def video_feed(camera_index):
    return Response(camera_streams[camera_index].generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
